{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8164262a-446c-4edf-93ab-a9616c3e81d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Live datanodes (2):\n"
     ]
    }
   ],
   "source": [
    "#q1\n",
    "!hdfs dfsadmin -fs hdfs://boss:9000 -report| grep \"Live datanodes\"\n",
    "\n",
    "\n",
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://pages.cs.wisc.edu/~harter/cs544/data/hdma-wi-2021.csv\", \"hdma-wi-2021.csv\")\n",
    "\n",
    "import pyarrow.csv as pv\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# df = pd.read_csv(\"hdma-wi-2021.csv\", low_memory=False)\n",
    "\n",
    "# table = pa.Table.from_pandas(df)\n",
    "csv_reader = pv.read_csv(\"hdma-wi-2021.csv\")\n",
    "pq.write_table(csv_reader, \"hdma-wi-2021.parquet\")\n",
    "\n",
    "! hdfs dfs -D dfs.block.size=1048576 -D dfs.replication=1 -cp /nb/hdma-wi-2021.parquet hdfs://boss:9000/single.parquet\n",
    "! hdfs dfs -D dfs.block.size=1048576 -D dfs.replication=2 -cp /nb/hdma-wi-2021.parquet hdfs://boss:9000/double.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f37b8a00-2ff7-46f5-9131-457e4c904996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.9 M  31.7 M  hdfs://boss:9000/double.parquet\n",
      "15.9 M  15.9 M  hdfs://boss:9000/single.parquet\n"
     ]
    }
   ],
   "source": [
    "#q2\n",
    "! hdfs dfs -du -h hdfs://boss:9000/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13130689-fdfa-4481-8db2-24e5b308736c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FileStatus': {'accessTime': 1729911971265,\n",
       "  'blockSize': 1048576,\n",
       "  'childrenNum': 0,\n",
       "  'fileId': 16386,\n",
       "  'group': 'supergroup',\n",
       "  'length': 16642976,\n",
       "  'modificationTime': 1729911972517,\n",
       "  'owner': 'root',\n",
       "  'pathSuffix': '',\n",
       "  'permission': '644',\n",
       "  'replication': 1,\n",
       "  'storagePolicy': 0,\n",
       "  'type': 'FILE'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q3\n",
    "import requests\n",
    "\n",
    "r= requests.get('http://boss:9870/webhdfs/v1/single.parquet?op=GETFILESTATUS')\n",
    "\n",
    "# print(r.json())\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc978dbc-4207-428e-8733-b905fa809294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Location': 'http://2c60d8032db3:9864/webhdfs/v1/single.parquet?op=OPEN&namenoderpcaddress=boss:9000&offset=0'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q4\n",
    "r= requests.get('http://boss:9870/webhdfs/v1/single.parquet?op=OPEN&offset=0&noredirect=true')\n",
    "\n",
    "# print(r.json())\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e61539cb-498f-4fb9-a1ba-59b082ea2d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2c60d8032db3': 9, 'e18610104cd6': 7}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q5\n",
    "from collections import defaultdict\n",
    "\n",
    "r= requests.get(\"http://boss:9870/webhdfs/v1/single.parquet?op=GETFILEBLOCKLOCATIONS\")\n",
    "\n",
    "\n",
    "dict= {}\n",
    "for topologyPath in r.json()[\"BlockLocations\"][\"BlockLocation\"]:\n",
    "    if (topologyPath[\"hosts\"][0] not in dict):\n",
    "        dict[topologyPath[\"hosts\"][0]]= 1\n",
    "    else:\n",
    "        dict[topologyPath[\"hosts\"][0]]+=1\n",
    "\n",
    "#dictionary file\n",
    "# print(dict)\n",
    "dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2349cf2-61c8-4bb4-9d7d-84c7227fb127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'e18610104cd6': 16, '2c60d8032db3': 16}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q6\n",
    "r= requests.get(\"http://boss:9870/webhdfs/v1/double.parquet?op=GETFILEBLOCKLOCATIONS\")\n",
    "# print(r.json())\n",
    "\n",
    "\n",
    "dict = {}\n",
    "\n",
    "for blk in r.json()[\"BlockLocations\"][\"BlockLocation\"]:\n",
    "\n",
    "    for host in blk[\"hosts\"]:\n",
    "\n",
    "        dict[host] = dict.get(host, 0) + 1\n",
    "\n",
    "dict\n",
    "\n",
    "\n",
    "# dict= {}\n",
    "# for topologyPath in r.json()[\"BlockLocations\"][\"BlockLocation\"]:\n",
    "#     if (topologyPath[\"hosts\"][0] not in dict):\n",
    "#         dict[topologyPath[\"hosts\"][0]]= 1\n",
    "#     else:\n",
    "#         dict[topologyPath[\"hosts\"][0]]+=1\n",
    "\n",
    "# print(dict)\n",
    "# dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72ad8d8d-e881-4e5a-a571-e1f5a2da7609",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-26 03:07:17,882 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(204961.21752386744)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q7\n",
    "import pyarrow as pa\n",
    "import pyarrow.fs\n",
    "import time\n",
    "\n",
    "hdfs = pa.fs.HadoopFileSystem(\"boss\", 9000)\n",
    "\n",
    "\n",
    "startTime = time.time()\n",
    "\n",
    "\n",
    "\n",
    "with hdfs.open_input_file(\"/single.parquet\") as f:\n",
    "    f\n",
    "    t = pa.parquet.read_table(f)\n",
    "\n",
    "\n",
    "loanCol = t['loan_amount']\n",
    "\n",
    "average = loanCol.to_pandas().mean()\n",
    "\n",
    "endTime = time.time()\n",
    "\n",
    "timeCost = endTime - startTime\n",
    "\n",
    "# print(average)\n",
    "average\n",
    "# print(timeCost)\n",
    "# timeCost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc0d7d27-c518-4a0d-9e9d-43198b6f70aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.89287155011037"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q8\n",
    "startTime = time.time()\n",
    "with hdfs.open_input_file(\"/single.parquet\") as f:\n",
    "    t = pa.parquet.read_table(f)\n",
    "loanCol = t['loan_amount']\n",
    "average = loanCol.to_pandas().mean()\n",
    "endTime = time.time()\n",
    "timeCost1 = endTime - startTime\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "startTime2 = time.time()\n",
    "\n",
    "with hdfs.open_input_file(\"/single.parquet\") as f:\n",
    "    loanCol = pa.parquet.read_table(f, columns=[\"loan_amount\"])\n",
    "    \n",
    "average = loanCol.to_pandas().mean()\n",
    "\n",
    "endTime2 = time.time()\n",
    "\n",
    "timeCost2 = endTime2 - startTime2\n",
    "\n",
    "diff= timeCost1/timeCost2\n",
    "# print(average)\n",
    "# print(timeCost)\n",
    "# print(diff)\n",
    "diff"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
